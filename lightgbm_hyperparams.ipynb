{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# hyperparameter tuning\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# model/grid search tracking\n",
    "import mlflow\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3597, 1: 598})\n",
      "Counter({1: 2994, 0: 2092})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4323, 16), (4323,), (763, 16), (763,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import convert_data, engineer_features, select_features\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "path = 'data\\\\train.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = convert_data(df)\n",
    "df = engineer_features(df)\n",
    "df = select_features(df)\n",
    "\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df.churn\n",
    "\n",
    "oversample = SMOTEENN()\n",
    "print(Counter(y))\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "print(Counter(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=59)\n",
    "\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, 0),\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 1, 100)),\n",
    "    'min_data_in_leaf': scope.int(hp.uniform('min_data_in_leaf', 1, 100)),\n",
    "    'num_leaves': scope.int(hp.uniform('num_leaves', 1, 100)),\n",
    "    'bagging_freq': hp.uniform('bagging_freq', 0.5, 1),\n",
    "    'bagging_fraction': hp.loguniform('bagging_fraction', -10, 0),  # subsample\n",
    "    'feature_fraction': hp.loguniform('feature_fraction', -10, 0),\n",
    "    'lambda_l1': hp.loguniform('lambda_l1', -10, 10),\n",
    "    'lambda_l2': hp.loguniform('lambda_l2', -10, 10),\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'eval_metric': 'auc',\n",
    "    'seed': 59,\n",
    "    'feature_fraction_seed': 59,\n",
    "    'bagging_seed': 59,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_model(params):\n",
    "    # With MLflow autologging, hyperparameters and the trained model are automatically logged to MLflow.\n",
    "    mlflow.lightgbm.autolog(silent=True)\n",
    "\n",
    "    # However, we can log additional information by using an MLFlow tracking context manager \n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        # Train model and record run time\n",
    "        start_time = time.time()\n",
    "        booster = lgb.train(params, lgb_train, num_boost_round=5000, valid_sets=lgb_eval,\n",
    "                            early_stopping_rounds=50, verbose_eval=False)\n",
    "        run_time = time.time() - start_time\n",
    "        mlflow.log_metric('runtime', run_time)\n",
    "\n",
    "        # Record AUC as primary loss for Hyperopt to minimize\n",
    "        predictions_test = booster.predict(lgb_eval)\n",
    "        \n",
    "        # F1-Score\n",
    "        f1score = f1_score(y_test, predictions_test)\n",
    "        mlflow.log_metric('f1', f1score)\n",
    "        \n",
    "        auc_score = roc_auc_score(y_test, predictions_test)\n",
    "\n",
    "        # Set the loss to -1*auc so fmin maximizes the auc_score\n",
    "        return {'status': STATUS_OK, 'loss': -auc_score, 'booster': booster.attributes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name='LGB-params')\n",
    "# runs initial search to assess 25 hyperparameter combinations\n",
    "with mlflow.start_run(run_name='LGB_Search'):\n",
    "    best_params = fmin(\n",
    "        fn=train_model,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=25,\n",
    "        rstate=np.random.default_rng(59),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e92dda350e586b0c334f0f5e12c30469449e88a6ff79a1f1c33a5faa01dbdb98"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
