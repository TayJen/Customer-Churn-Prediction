{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# hyperparameter tuning\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# model/grid search tracking\n",
    "import mlflow\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3597, 1: 598})\n",
      "Counter({1: 2955, 0: 2085})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4284, 16), (4284,), (756, 16), (756,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import convert_data, engineer_features, select_features\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "path = 'data\\\\train.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = convert_data(df)\n",
    "df = engineer_features(df)\n",
    "df = select_features(df)\n",
    "\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df.churn\n",
    "\n",
    "oversample = SMOTEENN()\n",
    "print(Counter(y))\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "print(Counter(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=59)\n",
    "\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Pool(data=X_train, label=y_train)\n",
    "test = Pool(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, 0),\n",
    "    'depth': scope.int(hp.uniform('max_depth', 1, 16)),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "    'bagging_temperature': hp.loguniform('gamma', -10, 10),\n",
    "    'random_strength': hp.loguniform('alpha', -10, 10),\n",
    "    'l2_leaf_reg': hp.loguniform('lambda', -10, 10),\n",
    "    'eval_metric': 'AUC',\n",
    "    'random_state': 59,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params):\n",
    "    # With MLflow autologging, hyperparameters and the trained model are automatically logged to MLflow.\n",
    "    # mlflow.catboost.autolog(silent=True)\n",
    "\n",
    "    # However, we can log additional information by using an MLFlow tracking context manager \n",
    "    with mlflow.start_run(nested=True):\n",
    "        cb = CatBoostClassifier(**params)\n",
    "        # Train model and record run time\n",
    "        start_time = time.time()\n",
    "        booster = cb.fit(train, eval_set=[test],\n",
    "                         early_stopping_rounds=50, verbose_eval=False)\n",
    "        run_time = time.time() - start_time\n",
    "        mlflow.log_metric('runtime', run_time)\n",
    "\n",
    "        # Record AUC as primary loss for Hyperopt to minimize\n",
    "        predictions_test = booster.predict(test)\n",
    "        auc_score = roc_auc_score(y_test, predictions_test)\n",
    "\n",
    "        # Set the loss to -1*f1_score so fmin maximizes the auc_score\n",
    "        return {'status': STATUS_OK, 'loss': -auc_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:33<00:00, 30.14s/trial, best loss: -0.9711105336105337] \n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name='CatBoost-params')\n",
    "# runs initial search to assess 25 hyperparameter combinations\n",
    "with mlflow.start_run(run_name='Cat_Search'):\n",
    "    best_params = fmin(\n",
    "        fn=train_model,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=25,\n",
    "        rstate=np.random.default_rng(59),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e92dda350e586b0c334f0f5e12c30469449e88a6ff79a1f1c33a5faa01dbdb98"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
